import numpy as np
import pyshac

np.random.seed(0)


# define the evaluation function
def squared_error_loss(id, parameters):
    x = parameters['x']
    y = parameters['y']
    y_sample = 2 * x - y

    # assume best values of x and y and 2 and 0 respectively
    y_true = 4.

    return np.square(y_sample - y_true)


# define the parameters
param_x = pyshac.UniformContinuousHyperParameter('x', -5.0, 5.0)
param_y = pyshac.UniformContinuousHyperParameter('y', -2.0, 2.0)

parameters = [param_x, param_y]

# Create a dataset file
# NOTE: This dataset file is NOT the same
# as the one generated by the engine when trained
# via SHAC.fit.
#
# All samples are drawn independently, and
# later sorted to provide an ever increasing
# cascade of samples for the classifiers.
with open('data.csv', 'w') as f:
    f.write('id,x,y,scores\n')
    f.flush()

    template = '%d,%0.4f,%0.4f,%0.5f\n'

    for i in range(2000):
        x = np.random.uniform(-5., 5.)
        y = np.random.uniform(-2., 2.)
        # Compute the MSE
        score = np.square(4. - (2 * x - y))

        f.write(template % (i, x, y, score))
        f.flush()

# define the total budget as 2000 evaluations
total_budget = 2000  # number of samples in the dataset (should be divisible by num batches)

# define the number of batches
num_batches = 10  # 10 samples per batch

# define the objective
objective = 'min'  # minimize the squared loss

shac = pyshac.SHAC(parameters, total_budget, num_batches, objective)

# train the classifiers using the pre-built dataset
# Use `presort` to improve the classifiers performance.
shac.fit_dataset('data.csv', presort=True)

# uncomment this if classifiers are already trained and only needs to predict
shac.restore_data()

# sample more than one batch of hyper parameters
parameter_samples = shac.predict(20)  # samples 20 hyper parameters

losses = [squared_error_loss(0, params) for params in parameter_samples]
x_list = [param['x'] for param in parameter_samples]
y_list = [param['y'] for param in parameter_samples]

for i, (x, y) in enumerate(zip(x_list, y_list)):
    print("Sample %d : (%0.4f, %0.4f)" % (i + 1, x, y))

print()
print("Mean squared error of samples : ", np.mean(losses))

# Visualize the dataset
from pyshac.utils.vis_utils import plot_dataset
plot_dataset(shac.dataset, eval_label='MSE')
